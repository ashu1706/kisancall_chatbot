{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdaf3f1d-5e67-4274-9383-a5b2dd7becf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Number of rows in the DataFrame: 473040\n",
      "         Date   State   Crop Growth_Stage  Rainfall_mm  Temp_Max_C  \\\n",
      "0  2022-01-01  Punjab  Wheat   Vegetative          0.0        14.9   \n",
      "1  2022-01-02  Punjab  Wheat   Vegetative          0.0        12.1   \n",
      "2  2022-01-03  Punjab  Wheat    Flowering          0.0        13.7   \n",
      "3  2022-01-04  Punjab  Wheat    Flowering          1.0        13.8   \n",
      "4  2022-01-05  Punjab  Wheat    Flowering          0.0        12.5   \n",
      "\n",
      "   Temp_Min_C  Humidity_Percent Soil_Type  Soil_Moisture_Percent  \\\n",
      "0         7.2              30.5     Silty                   32.3   \n",
      "1         7.3              42.0     Silty                   37.4   \n",
      "2         8.6              46.0     Silty                   41.2   \n",
      "3         6.9              35.9     Silty                   44.1   \n",
      "4         6.9              39.2     Silty                   40.0   \n",
      "\n",
      "   Irrigation_Required_mm  \n",
      "0                    4.31  \n",
      "1                    3.97  \n",
      "2                    5.32  \n",
      "3                    4.63  \n",
      "4                    5.40  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Corrected File Path (if needed) and Load\n",
    "try:\n",
    "    df = pd.read_csv('crop_irrigation_synth_2years.csv')\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'crop_irrigation_synth_2years.csv' was not found. Please ensure it is in the same directory.\")\n",
    "\n",
    "# **CRITICAL: Add this line to check the number of rows**\n",
    "print(f\"Number of rows in the DataFrame: {len(df)}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b145ea8-34f7-4be8-9748-7f5cd87c8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(['Irrigation_Required_mm', 'Date'], axis=1)\n",
    "y = df['Irrigation_Required_mm']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_features = ['State', 'Crop', 'Growth_Stage', 'Soil_Type']\n",
    "numerical_features = ['Rainfall_mm', 'Temp_Max_C', 'Temp_Min_C', 'Humidity_Percent', 'Soil_Moisture_Percent']\n",
    "\n",
    "# Create a preprocessor with OneHotEncoder\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Apply the preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c983ce36-1468-4f6d-9f0d-6b32ddd41964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a363c1a-d69f-44ef-94ef-07fd4601f1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.01 mm\n",
      "Root Mean Squared Error (RMSE): 0.02 mm\n",
      "R-squared (R2) Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f} mm\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f} mm\")\n",
    "print(f\"R-squared (R2) Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d117f5ba-83d2-4d89-8bbb-f9be602c3b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created at: D:/my_models/\n",
      "Models and preprocessor saved to: D:/my_models/\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the directory where you want to save the files on the D: drive\n",
    "save_path = 'D:/my_models/'\n",
    "\n",
    "# Check if the directory exists, and if not, create it\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    print(f\"Directory created at: {save_path}\")\n",
    "\n",
    "# Now, save the trained model and preprocessor to the specified path\n",
    "joblib.dump(model, os.path.join(save_path, 'irrigation_model.joblib'))\n",
    "joblib.dump(preprocessor, os.path.join(save_path, 'data_preprocessor.joblib'))\n",
    "\n",
    "print(f\"Models and preprocessor saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25c7f4-877e-462b-9a35-7670733d65c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
